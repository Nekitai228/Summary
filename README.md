# Text Summarizer(Для GenAI-1-35)

Модуль для автоматического создания кратких содержаний научных текстов с использованием модели машинного обучения.

## Описание

Данный скрипт использует предобученную модель BART-large-CNN от Facebook для генерации сжатых версий научных текстов. Модель автоматически выделяет ключевые идеи и основные положения исходного текста, создавая краткое содержание длиной до 100 слов.

## Особенности

- Автоматическое суммирование научных текстов
- Ограничение результата до 100 слов
- Очистка текста от лишних пробелов и форматирования
- Возвращает как сжатый текст, так и количество слов в нем

## Установка зависимостей

```bash
pip install transformers torch
```
## Использование

# Простое использование
```python
from summarizer import summarize

text = "Ваш научный текст здесь..."
summary, word_count = summarize(text)

print("Краткое содержание:")
print(summary)
print(f"Количество слов: {word_count}")
```
## Запуск скрипта
```bash
python summarizer.py
```
Затем введите текст для суммаризации.

## Параметры модели
Модель: facebook/bart-large-cnn

Максимальная длина: 100 слов

Минимальная длина: 30 слов

Усечение: Включено

Сэмплирование: Отключено

## Обработка ошибок
Скрипт включает комплексную обработку ошибок:

Пустой текст: Проверка на пустые или отсутствующие входные данные

Слишком короткий текст: Минимальная длина текста для суммаризации

Ошибки загрузки модели: Проблемы с загрузкой предобученной модели

Ошибки суммаризации: Проблемы в процессе обработки текста моделью

Непредвиденные ошибки: Общий обработчик для непредвиденных ситуаций

## Требования
Python 3.6+

transformers >= 4.0.0

torch

re (входит в стандартную библиотеку Python)

## Ограничения
Предназначен в первую очередь для научных текстов

Максимальная длина входного текста ограничена возможностями модели

Качество суммаризации зависит от исходного текста

## Пример работы
# Вход:
"Недавние исследования в области искусственного интеллекта показали значительный прогресс в обработке естественного языка.
Трансформерные архитектуры, такие как BERT и GPT, revolutionized how machines understand human language.
These advancements have led to improvements in machine translation, text summarization, and question-answering systems."

# Выход:
Краткое содержание:
Recent research in artificial intelligence has shown significant progress in natural language processing.
Transformer architectures like BERT and GPT have revolutionized how machines understand human language, leading to improvements in machine translation and text summarization.

Количество слов: 25

# Примечания
Модель загружается при первом вызове функции summarize, что может занять некоторое время и потребовать значительных ресурсов памяти.






# Text Summarizer with Keyword Annotation(Для GenAI-2-35)

Модуль для автоматического создания краткого содержания научных текстов с генерацией аннотаций, включающих заданные ключевые слова.

## Описание

Этот скрипт использует предобученную модель BART-large-CNN от Facebook для генерации сжатых версий научных текстов. Модель автоматически выделяет ключевые моменты исходного текста и создает краткое изложение. Дополнительная функция позволяет гарантировать включение заданных ключевых слов в итоговую аннотацию.

## Особенности

- **Автоматическая суммаризация** научных текстов на английском языке
- **Генерация аннотаций** с обязательным включением ключевых слов
- **Проверка наличия ключевых слов** в результирующем тексте
- **Обработка ошибок** и валидация входных данных
- **Ограничение длины** результата (до 100 слов)

## Установка зависимостей

```bash
pip install transformers torch
```

## Использование
# Основные функции
Функция summarize(text: str) -> Tuple[str, int]
Создает краткое содержание текста.
```python
from text_summarizer import summarize

text = "Your scientific text here..."
summary, word_count = summarize(text)

print("Краткое содержание:")
print(summary)
print(f"Количество слов: {word_count}")
```
Функция generate_annotation_with_keywords(text: str, keywords: List[str]) -> Dict
Генерирует аннотацию с обязательным включением ключевых слов.

```python
from text_summarizer import generate_annotation_with_keywords

text = "Your research paper text..."
keywords = ['neural networks', 'training', 'data']

result = generate_annotation_with_keywords(text, keywords)
print("Аннотация:", result['annotation'])
print("Количество слов:", result['word_count'])
print("Все ключевые слова присутствуют:", result['keywords_present'])
```
# Запуск из командной строки
```bash
python GenAI-2-35.py
```
После запуска введите текст статьи для обработки. Скрипт автоматически сгенерирует аннотацию с ключевыми словами: 'Нейросети', 'Обучение', 'Данные'.

## Параметры конфигурации
В начале скрипта определены глобальные константы для настройки:
```python
MODEL_NAME = "facebook/bart-large-cnn"  # Используемая модель
MAX_SUMMARY_LENGTH = 100                # Максимальная длина аннотации (слов)
MIN_SUMMARY_LENGTH = 30                 # Минимальная длина аннотации (слов)
MIN_INPUT_WORDS = 10                    # Минимальная длина входного текста
```

# Обработка ошибок
Скрипт обрабатывает следующие типы ошибок:

ValueError: Неверные входные данные (пустой текст, неправильный тип)

RuntimeError: Ошибки загрузки модели или процесса суммаризации

Exception: Непредвиденные ошибки

KeyboardInterrupt: Прерывание программы пользователем

# Требования
Python 3.6+

transformers >= 4.0.0

torch

re (входит в стандартную библиотеку Python)

# Ограничения
Модель оптимизирована для английского языка

Рекомендуется использовать с научными и академическими текстами

Минимальная длина входного текста: 10 слов

Для очень длинных текстов может потребоваться предварительное разделение на части

## Пример выходных данных
```text
==================================================
АННОТАЦИЯ:
==================================================
This research explores modern approaches to neural network training with emphasis on data quality and preprocessing techniques. The work pays special attention to neural networks, training, data.

Количество слов: 28

ПРОВЕРКА КЛЮЧЕВЫХ СЛОВ:
Yes neural networks
Yes training
Yes data
```

# Примечания
При первом запуске скрипт загрузит предобученную модель (≈1.6 ГБ), что может занять некоторое время. Последующие запуски будут использовать кэшированную версию модели.

# Лицензия




# Automated Article Annotation System(Для GenAI-3-04)

Система для автоматической обработки научных статей с извлечением ключевых слов, генерацией аннотаций и сохранением результатов.

## Описание

Данный скрипт предоставляет комплексное решение для анализа научных статей, включающее:
- Автоматическое извлечение ключевых слов из текста
- Генерацию аннотаций с обязательным включением ключевых слов
- Ограничение длины аннотации до 150 слов
- Автоматическое сохранение результатов в файл

## Основные возможности

- **Интеллектуальное извлечение ключевых слов** с использованием модели KeyBERT
- **Качественная суммаризация** на основе модели BART-large-CNN
- **Гарантированное включение ключевых слов** в итоговую аннотацию
- **Автоматическое сохранение** результатов с временными метками
- **Подробная отчетность** о процессе обработки

## Установка зависимостей

```bash
pip install transformers torch keybert sentence-transformers
Модель BART-large-CNN предоставляется Facebook под лицензией MIT.
```

# Архитектура системы
## Модели и технологии
Модель суммаризации: facebook/bart-large-cnn

Модель извлечения ключевых слов: KeyBERT с sentence-transformers

Обработка текста: регулярные выражения для очистки текста

Формат сохранения: текстовые файлы с подробной структурой

## Основные функции
initialize_models()
Инициализирует обе модели при запуске приложения.

extract_keywords(text: str, num_keywords: int = 5)
Извлекает ключевые слова из текста с настраиваемым количеством.

summarize(text: str)
Создает краткое содержание текста длиной до 150 слов.

generate_annotation_with_keywords(text: str, keywords: List[str])
Генерирует аннотацию с гарантированным включением ключевых слов.

save_results(annotation_data: Dict, original_text: str, filename: str = None)
Сохраняет все результаты обработки в структурированный файл.

# Использование
## Запуск приложения
```bash
python GenAI-3-04.py
```
## Процесс работы
1)Ввод текста статьи - пользователь вводит текст для обработки

2)Автоматическое извлечение ключевых слов - система определяет 5 наиболее релевантных терминов

3)Генерация аннотации - создается краткое содержание с включением ключевых слов

4)Сохранение результатов - все данные сохраняются в файл с временной меткой


# Пример выходных данных
============================================================
РЕЗУЛЬТАТЫ АННОТАЦИИ СТАТЬИ
============================================================

ИСХОДНЫЙ ТЕКСТ:
----------------------------------------
[Первые 500 символов текста]...

АННОТАЦИЯ:
----------------------------------------
Сгенерированная аннотация текста с включенными ключевыми словами...

Количество слов: 142

КЛЮЧЕВЫЕ СЛОВА:
----------------------------------------
✓ машинное обучение
✓ нейронные сети
✓ обработка данных
✓ алгоритмы
✓ искусственный интеллект

Все ключевые слова присутствуют: Да

Файл сохранен: annotation_results_20231201_143022.txt
Время создания: 2023-12-01 14:30:22

# Конфигурация
## Параметры системы
```python
MODEL_NAME = "facebook/bart-large-cnn"  # Модель для суммаризации
MAX_SUMMARY_LENGTH = 150               # Макс. длина аннотации
MIN_SUMMARY_LENGTH = 50                # Мин. длина аннотации
MIN_INPUT_WORDS = 10                   # Мин. длина входного текста
```
## Настройка извлечения ключевых слов
keyphrase_ngram_range=(1, 2) - униграммы и биграммы

stop_words='english' - фильтрация стоп-слов

top_n=5 - количество извлекаемых ключевых слов

diversity=0.5 - баланс между релевантностью и разнообразием

# Обработка ошибок
Система обрабатывает следующие типы ошибок:
ValueError: Невалидные входные данные

RuntimeError: Ошибки загрузки моделей и обработки

Exception: Непредвиденные ошибки

KeyboardInterrupt: Прерывание пользователем

# Требования
Python 3.7+

transformers >= 4.20.0

torch >= 1.9.0

keybert >= 0.7.0

sentence-transformers >= 2.2.0

# Особенности работы
## Извлечение ключевых слов
Используется комбинация embedding-моделей для определения наиболее релевантных терминов в контексте документа.

## Суммаризация
Модель BART fine-tuned на задаче суммаризации новостных статей, что обеспечивает высокое качество аннотаций.

## Обработка длинных текстов
Система автоматически обрезает текст при необходимости и обеспечивает соответствие ограничению в 150 слов.

# Пример использования в коде
```python
from GenAI-3-04 import initialize_models, extract_keywords, generate_annotation_with_keywords

# Инициализация моделей
initialize_models()

# Обработка статьи
text = "Ваш научный текст здесь..."
keywords = extract_keywords(text)
result = generate_annotation_with_keywords(text, keywords)

print(f"Аннотация: {result['annotation']}")
print(f"Ключевые слова: {result['keywords']}")
```

## Примечания
При первом запуске происходит загрузка моделей (≈2 ГБ)

Рекомендуется использование с научными и техническими текстами

Система оптимизирована для работы на английском языке

Для очень больших документов рекомендуется предварительное разделение на секции

# Лицензия
Модели распространяются под соответствующими лицензиями:

BART-large-CNN: MIT License

KeyBERT: MIT License

